<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AMAF-Net: Adaptive Multi-modal Alignment Framework</title>
  <link rel="stylesheet" href="style.css">
</head>

<body>

<div class="container">

  <h1>AMAF-Net: Adaptive Multi-modal Alignment Framework for Counterfeit Fruit Recognition</h1>
  <h3>
  Quynh Nguyen Huu1*, Dat Tran-Anh2*, Thieu Huy Nguyen2, Ngoc Anh Nguyen Thi1, Nguyen Huu Gia Bach3 

1CMC University, Hanoi, Vietnam;
2Faculty of Information Technology, Thuyloi University, Hanoi, Vietnam;
3Yen Hoa High School, Hanoi, Vietnam
*Corresponding author
  </h3>
  <h3>Conference: International Conference on Artificial Intelligence: Impacts and Potentials 2025</h3>
  <p class="authors">
    <strong>Authors:</strong> Nguyen Thieu Huy, Le Hong Ngoc, ‚Ä¶
  </p>

  <div class="links">
    <a href="ICAI-IP2025-paper-final (1).pdf">üìÑ Paper</a>
    <a href="ICAI-IP poster.pdf">üñºÔ∏è Poster</a>
    <a href="https://github.com/ThieuHuy43/TF-MCA" target="_blank">üíª Code</a>
  </div>

  <h2>Abstract</h2>
  <p>
    Fine-grained counterfeit detection remains a challenge due to subtle visual differences, limited samples, and modality inconsistencies between vision and language. We introduce AMAF-Net, an Adaptive Multi-modal Alignment Framework designed for training-free fine-grained recognition. It enhances textual semantics through attribute-guided prompts generated by large language models and refines visual prototypes via base knowledge anchoring. An adaptive fusion mechanism dynamically balances both modalities using confidence-based weighting complemented by lightweight metric refinement. Without retraining, AMAF-Net achieves 90.2% accuracy on the FG-Fruit dataset, surpassing existing vision‚Äìlanguage baselines by up to 5% and demonstrating strong efficiency and robustness for fine-grained counterfeit recognition.
  </p>

  <h2>Method Overview</h2>
  <img src="model_architecture2.pptx" alt="method figure" class="figure">

  <h2>Key Results</h2>
  <ul>
    <li>Highest overall accuracy across all benchmark sessions</li>
    <li>Low forgetting and stable performance curve</li>
    <li>Strong fine-grained recognition capability</li>
    <li>Effective for counterfeit fruit detection in real-world settings</li>
  </ul>

  <h2>BibTeX</h2>
  <pre>
@inproceedings{huy2025amafnet,
  title={AMAF-Net: Adaptive Multi-modal Alignment Framework},
  author={...},
  booktitle={International Conference on AI: Impacts and Potentials},
  year={2025}
}
  </pre>

</div>

</body>
</html>
