<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AMAF-Net: Adaptive Multi-modal Alignment Framework</title>
  <link rel="stylesheet" href="style.css">
</head>

<body>

<div class="container">

  <h1>Training-Free Multil-Modal Alignment for Fine-Grained Couterfeit Fruit Detection</h1>
  <p class="affiliation">
  Quynh Nguyen Huu<sup>1*</sup>, Dat Tran-Anh<sup>2*</sup>, Thieu Huy Nguyen<sup>2</sup>, Ngoc Anh Nguyen Thi<sup>1</sup>, Nguyen Huu Gia Bach<sup>3</sup><br>
  <br>
  <sup>1</sup>CMC University, Hanoi, Vietnam<br>
  <sup>2</sup>Faculty of Information Technology, Thuyloi University, Hanoi, Vietnam<br>
  <sup>3</sup>Yen Hoa High School, Hanoi, Vietnam<br>
  <br>
  *Corresponding author
  </p>

  <h3 class="conference">International Conference on Artificial Intelligence: Impacts and Potentials 2025</h3>

  <div class="links">
    <a href="ICAI-IP2025-paper-final.pdf">üìÑ Full Paper</a>
    <a href="ICAI-IP_POSTER_75.pdf">üñºÔ∏è Poster</a>
    <!-- <a href="https://github.com/ThieuHuy43/TF-MCA" target="_blank">üíª Code</a> -->
  </div>

  <h2>Abstract</h2>
  <p class="abstract">
    Fine-grained counterfeit detection remains a challenge due to subtle visual differences, limited samples, and modality inconsistencies between vision and language. We introduce AMAF-Net, an Adaptive Multi-modal Alignment Framework designed for training-free fine-grained recognition. It enhances textual semantics through attribute-guided prompts generated by large language models and refines visual prototypes via base knowledge anchoring. An adaptive fusion mechanism dynamically balances both modalities using confidence-based weighting complemented by lightweight metric refinement. Without retraining, AMAF-Net achieves 90.2% accuracy on the FG-Fruit dataset, surpassing existing vision‚Äìlanguage baselines by up to 5% and demonstrating strong efficiency and robustness for fine-grained counterfeit recognition.
  </p>

  <h2>Method Overview</h2>
  <img src="model.png" alt="method figure" class="figure">

  <h2>Key Results</h2>
  <ul>
    <li>Highest overall accuracy across all benchmark sessions</li>
    <li>Low forgetting and stable performance curve</li>
    <li>Strong fine-grained recognition capability</li>
    <li>Effective for counterfeit fruit detection in real-world settings</li>
  </ul>

  <h2>BibTeX</h2>
  <!-- <pre>
@inproceedings{huy2025amafnet,
  title={AMAF-Net: Adaptive Multi-modal Alignment Framework},
  author={...},
  booktitle={International Conference on AI: Impacts and Potentials},
  year={2025}
}
  </pre> -->

</div>

</body>
</html>
